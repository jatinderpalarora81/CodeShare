@startuml

title Spring Batch Job Manager Service - API Control for Multiple Jobs

'Legend'
legend right
  [C4 Level 2: Container Diagram]
  - The Job Manager Service provides APIs for controlling batch jobs.
  - Each Spring Batch job runs in a separate JVM.
  - The Job Manager Service interacts with the Spring Batch jobs and repository through a common interface.
endlegend

package "Job Manager Service" {
  component JobManagerService as "Job Manager Service" <<Component>> {
    ..Control APIs..
    * start(String jobName, Properties parameters) : Long
    * restart(Long executionId) : Long
    * stop(Long executionId) : boolean
    * getRunningExecutions(String jobName) : Set<Long>
    
    ..Getter APIs..
    * getJobInstances(String jobName, int start, int count) : List<Long>
    * getJobNames() : Set<String>
    * getSummary(Long executionId) : String
    * getParameters(Long executionId) : String
  }

  interface JobOperator {
    + start(String jobName, Properties parameters)
    + restart(Long executionId)
    + stop(Long executionId)
    + getJobExecutions(String jobName)
  }
}

package "Spring Batch Jobs (JVMs)" {
  component SpringBatchJob1 as "Spring Batch Job 1 (JVM1)" <<BatchJob>> {
    ..Job Control Methods..
    * beforeJob(JobExecution jobExecution)
    * afterJob(JobExecution jobExecution)
    * beforeStep(StepExecution stepExecution)
    * afterStep(StepExecution stepExecution)
    
    ..Chunk and Read Listeners..
    * beforeChunk(ChunkContext chunkContext)
    * afterChunk(ChunkContext chunkContext)
    * beforeRead()
    * afterRead(T item)
  }

  component SpringBatchJob2 as "Spring Batch Job 2 (JVM2)" <<BatchJob>> {
    ..Job Control Methods..
    * beforeJob(JobExecution jobExecution)
    * afterJob(JobExecution jobExecution)
    * beforeStep(StepExecution stepExecution)
    * afterStep(StepExecution stepExecution)
    
    ..Chunk and Read Listeners..
    * beforeChunk(ChunkContext chunkContext)
    * afterChunk(ChunkContext chunkContext)
    * beforeRead()
    * afterRead(T item)
  }
}

package "Common Resources" {
  database JobRepository as "Job Repository (Database)" <<Database>> {
    [job_execution]
    [step_execution]
    [job_instance]
  }
}

'Relationships'
JobManagerService - JobOperator : "Uses JobOperator"
JobManagerService -down- JobRepository : "Read/Write job execution data"
SpringBatchJob1 -down- JobRepository : "Read/Write job data"
SpringBatchJob2 -down- JobRepository : "Read/Write job data"
JobManagerService -down- SpringBatchJob1 : "Control APIs"
JobManagerService -down- SpringBatchJob2 : "Control APIs"

note right of JobManagerService
  Job Manager Service exposes APIs to:
  - Start, stop, and restart jobs.
  - Fetch job status and instances.
  - Handle listeners for job lifecycle events.
end note

note bottom of SpringBatchJob1
  Job1 Lifecycle Listeners:
  - beforeJob, afterJob
  - beforeStep, afterStep
  - beforeChunk, afterChunk
  - beforeRead, afterRead
end note

note bottom of SpringBatchJob2
  Job2 Lifecycle Listeners:
  - beforeJob, afterJob
  - beforeStep, afterStep
  - beforeChunk, afterChunk
  - beforeRead, afterRead
end note

@enduml






-



This diagram shows:

A Job Manager Service which provides the interface for job control (start, stop, restart, etc.).
Multiple Spring Batch Job Applications (Job1, Job2, etc.) running in separate JVMs.
Each job exposes Listener APIs for various job lifecycle events (before/after job, step, chunk, etc.).
The Job Repository, where job execution and status are stored.
puml
Copy code
@startuml

!define RECTANGLE

title Generic API Interface for Spring Batch Jobs

'Legend'
legend right
  [C4 Level 2: System Container Diagram]
  - Job Manager Service exposes APIs to control batch jobs.
  - Each batch job (Job1, Job2, etc.) runs in a separate JVM.
  - The job control APIs interact with Spring Batch through JobOperator.
  - Listeners are exposed for job lifecycle events.
endlegend

'Spring Batch Architecture'
RECTANGLE JobManagerService as "Job Manager Service" <<Component>> {
  [start(String jobName, Properties parameters) : Long]
  [restart(long executionId) : Long]
  [stop(long executionId) : boolean]
  [getRunningExecutions(String jobName) : Set<Long>]
  [getJobInstances(String jobName, int start, int count) : List<Long>]
  [getSummary(long executionId) : String]
  [getJobNames() : Set<String>]
}

RECTANGLE SpringBatchJob1 as "Spring Batch Job1 (JVM1)" <<Container>> {
  [Job1Application] <<BatchJob>>
  [beforeJob(JobExecution jobExecution)]
  [afterJob(JobExecution jobExecution)]
  [beforeStep(StepExecution stepExecution)]
  [afterStep(StepExecution stepExecution)]
  [beforeChunk(ChunkContext chunkContext)]
  [afterChunk(ChunkContext chunkContext)]
  [beforeRead()]
  [afterRead(T item)]
}

RECTANGLE SpringBatchJob2 as "Spring Batch Job2 (JVM2)" <<Container>> {
  [Job2Application] <<BatchJob>>
  [beforeJob(JobExecution jobExecution)]
  [afterJob(JobExecution jobExecution)]
  [beforeStep(StepExecution stepExecution)]
  [afterStep(StepExecution stepExecution)]
  [beforeChunk(ChunkContext chunkContext)]
  [afterChunk(ChunkContext chunkContext)]
  [beforeRead()]
  [afterRead(T item)]
}

'Job Repository for storing job details and execution information'
RECTANGLE JobRepository as "Job Repository (Database)" <<Database>> {
  [job_execution]
  [step_execution]
  [job_instance]
}

JobManagerService -down- JobRepository : "Job execution control"
JobManagerService -down- SpringBatchJob1 : "API control & status"
JobManagerService -down- SpringBatchJob2 : "API control & status"
SpringBatchJob1 -down- JobRepository : "Read/Write Job Execution Data"
SpringBatchJob2 -down- JobRepository : "Read/Write Job Execution Data"

note right of JobManagerService
  Job Manager Service exposes:
  - Job control APIs (start, stop, restart, etc.)
  - Job status & summary retrieval (getRunningExecutions, getJobNames, getSummary)
  - Listener APIs for job lifecycle (beforeJob, afterJob, etc.)
end note

note right of SpringBatchJob1
  Job1 lifecycle listeners:
  - beforeJob, afterJob
  - beforeStep, afterStep
  - beforeChunk, afterChunk
  - beforeRead, afterRead
end note

note right of SpringBatchJob2
  Job2 lifecycle listeners:
  - beforeJob, afterJob
  - beforeStep, afterStep
  - beforeChunk, afterChunk
  - beforeRead, afterRead
end note

@enduml
Breakdown of Key Components:
Job Manager Service:

Exposes the generic API interface to control all jobs (start, stop, restart, etc.).
Implements methods like:
start(String jobName, Properties parameters)
restart(long executionId)
stop(long executionId)
getRunningExecutions(String jobName)
getJobNames(), etc.
Interacts with the Spring Batch JobOperator to manage jobs.
Spring Batch Job Applications:

Each job (Job1, Job2, etc.) is running as a standalone Spring Batch job in its own JVM.
Each job application exposes Listener APIs to monitor job lifecycle events, like:
beforeJob(JobExecution jobExecution)
afterJob(JobExecution jobExecution)
beforeStep(StepExecution stepExecution)
afterStep(StepExecution stepExecution)
beforeRead()
afterRead(T item)
beforeChunk(ChunkContext chunkContext)
afterChunk(ChunkContext chunkContext)
Job Repository:

The Job Repository (database) is used to store job instances, execution details, and status.
Both Job1 and Job2 interact with the job repository to update their execution status, parameters, and other metadata.
How the Diagram Depicts the Architecture:
The Job Manager Service provides an interface for job control and job status operations, while each job (Job1, Job2) runs in a separate JVM.
Each job has lifecycle listeners (beforeJob, afterJob, etc.) for monitoring different phases of the job execution.
All jobs interact with the Job Repository for reading and writing job execution data.
This UML diagram helps to visualize the architecture of a distributed Spring Batch job system with a central API controller.


import os
import csv
import shutil

def find_web_files(java_filename):
    # Replace .java with .html and .jsp in the file name
    html_filename = java_filename.replace(".java", ".html")
    jsp_filename = java_filename.replace(".java", ".jsp")
    return html_filename, jsp_filename

def search_web_files(directory, java_files):
    web_files = set()
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith((".html", ".jsp")):
                web_files.add(file)
    return web_files

def create_missing_files_csv(csv_file, code_directory, output_csv):
    # Read the CSV file to get the list of .java files
    with open(csv_file, 'r') as csvfile:
        reader = csv.reader(csvfile)
        java_files = [row[0] for row in reader]

    # Search for corresponding .html and .jsp files in the code base
    web_files = search_web_files(code_directory, java_files)

    # Find files with no corresponding .html or .jsp version
    missing_files = set(java_files) - web_files

    # Create a new CSV file with missing files
    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        for missing_file in missing_files:
            writer.writerow([missing_file])

    # Copy missing .java files to a new directory if needed
    for missing_file in missing_files:
        src_path = os.path.join(code_directory, missing_file)
        dest_path = os.path.join('new_files_directory', missing_file)
        shutil.copy2(src_path, dest_path)

if __name__ == "__main__":
    # Replace 'your_csv_file.csv', 'your_code_directory', and 'output_csv_file.csv' with actual paths
    csv_file_path = 'your_csv_file.csv'
    code_directory_path = 'your_code_directory'
    output_csv_path = 'output_csv_file.csv'

    create_missing_files_csv(csv_file_path, code_directory_path, output_csv_path)













from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain.vectorstores import DocArrayInMemorySearch
from langchain.document_loaders import TextLoader
from langchain.chains import RetrievalQA,  ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader
from langchain.document_loaders import PyPDFLoader

def load_db(file, chain_type, k):
    # load documents
    loader = PyPDFLoader(file)
    documents = loader.load()
    # split documents
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    docs = text_splitter.split_documents(documents)
    # define embedding
    embeddings = OpenAIEmbeddings(openai_api_key='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')
    # create vector database from data
    db = DocArrayInMemorySearch.from_documents(docs, embeddings)
    # define retriever
    retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": k})
    # create a chatbot chain. Memory is managed externally.
    qa = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key='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'), 
        chain_type=chain_type, 
        retriever=retriever, 
        return_source_documents=True,
        return_generated_question=True,
    )
    return qa 


import os
import openai
import sys
sys.path.append('../..')

import panel as pn  # GUI
pn.extension()

from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file

openai.api_key  = os.environ['LOGNAME']
print(openai.api_key )
# os.environ['OPENAI_API_KEY']
# OPENAI_API_KEY='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'


import datetime
current_date = datetime.datetime.now().date()
if current_date < datetime.date(2023, 9, 2):
    llm_name = "gpt-3.5-turbo-0301"
else:
    llm_name = "gpt-3.5-turbo"
print(llm_name)


import panel as pn
import param

class cbfs(param.Parameterized):
    chat_history = param.List([])
    answer = param.String("")
    db_query  = param.String("")
    db_response = param.List([])
    
    def __init__(self,  **params):
        super(cbfs, self).__init__( **params)
        self.panels = []
        self.loaded_file = "./b1.pdf"
        self.qa = load_db(self.loaded_file,"stuff", 4)
    
    def call_load_db(self, count):
        if count == 0 or file_input.value is None:  # init or no file specified :
            return pn.pane.Markdown(f"Loaded File: {self.loaded_file}")
        else:
            file_input.save("temp.pdf")  # local copy
            self.loaded_file = file_input.filename
            button_load.button_style="outline"
            self.qa = load_db("temp.pdf", "stuff", 4)
            button_load.button_style="solid"
        self.clr_history()
        return pn.pane.Markdown(f"Loaded File: {self.loaded_file}")

    def convchain(self, query):
        if not query:
            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown("", width=600)), scroll=True)
        result = self.qa({"question": query, "chat_history": self.chat_history})
        self.chat_history.extend([(query, result["answer"])])
        self.db_query = result["generated_question"]
        self.db_response = result["source_documents"]
        self.answer = result['answer'] 
        self.panels.extend([
            pn.Row('User:', pn.pane.Markdown(query, width=600)),
            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))
        ])
        inp.value = ''  #clears loading indicator when cleared
        return pn.WidgetBox(*self.panels,scroll=True)

    @param.depends('db_query ', )
    def get_lquest(self):
        if not self.db_query :
            return pn.Column(
                pn.Row(pn.pane.Markdown(f"Last question to DB:", styles={'background-color': '#F6F6F6'})),
                pn.Row(pn.pane.Str("no DB accesses so far"))
            )
        return pn.Column(
            pn.Row(pn.pane.Markdown(f"DB query:", styles={'background-color': '#F6F6F6'})),
            pn.pane.Str(self.db_query )
        )

    @param.depends('db_response', )
    def get_sources(self):
        if not self.db_response:
            return 
        rlist=[pn.Row(pn.pane.Markdown(f"Result of DB lookup:", styles={'background-color': '#F6F6F6'}))]
        for doc in self.db_response:
            rlist.append(pn.Row(pn.pane.Str(doc)))
        return pn.WidgetBox(*rlist, width=600, scroll=True)

    @param.depends('convchain', 'clr_history') 
    def get_chats(self):
        if not self.chat_history:
            return pn.WidgetBox(pn.Row(pn.pane.Str("No History Yet")), width=600, scroll=True)
        rlist=[pn.Row(pn.pane.Markdown(f"Current Chat History variable", styles={'background-color': '#F6F6F6'}))]
        for exchange in self.chat_history:
            rlist.append(pn.Row(pn.pane.Str(exchange)))
        return pn.WidgetBox(*rlist, width=600, scroll=True)

    def clr_history(self,count=0):
        self.chat_history = []
        return 


cb = cbfs()

file_input = pn.widgets.FileInput(accept='.pdf')
button_load = pn.widgets.Button(name="Load DB", button_type='primary')
button_clearhistory = pn.widgets.Button(name="Clear History", button_type='warning')
button_clearhistory.on_click(cb.clr_history)
inp = pn.widgets.TextInput( placeholder='Enter text here…')

bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)
conversation = pn.bind(cb.convchain, inp) 

jpg_pane = pn.pane.Image( './Downloads/marker23.jpg')

tab1 = pn.Column(
    pn.Row(inp),
    pn.layout.Divider(),
    pn.panel(conversation,  loading_indicator=True, height=300),
    pn.layout.Divider(),
)
tab2= pn.Column(
    pn.panel(cb.get_lquest),
    pn.layout.Divider(),
    pn.panel(cb.get_sources ),
)
tab3= pn.Column(
    pn.panel(cb.get_chats),
    pn.layout.Divider(),
)
tab4=pn.Column(
    pn.Row( file_input, button_load, bound_button_load),
    pn.Row( button_clearhistory, pn.pane.Markdown("Clears chat history. Can use to start a new topic" )),
    pn.layout.Divider(),
    pn.Row(jpg_pane.clone(width=400))
)
dashboard = pn.Column(
    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),
    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))
)
dashboard
